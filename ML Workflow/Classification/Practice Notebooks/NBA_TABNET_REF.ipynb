{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5657516c-f06c-4136-8f19-fd596ed9afd2",
   "metadata": {},
   "source": [
    "**<font size = 4> <font color = 'red'> IMPORT MODULES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dce9de-dea3-4f34-a218-9b61824acc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a5b2f9-3b12-42f0-ad31-c3b1004e8041",
   "metadata": {},
   "source": [
    "**<font size = 4> <font color = 'red'> SETTING SEEDS (IMPORTANT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc7af2-d651-45f3-9b35-6aa8c6727116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set a fixed seed value\n",
    "seed_value = 10\n",
    "\n",
    "# 1. Set PYTHONHASHSEED environment variable for reproducibility in hashing\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# 2. Set the seed for Python's built-in random module\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the seed for NumPy\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the seed for PyTorch\n",
    "torch.manual_seed(seed_value)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "# 5. Force PyTorch to use deterministic algorithms (may impact performance)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "# 6. Optionally limit the number of threads used by OMP and MKL (helps reduce non-determinism)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "print(\"Seeds and environment variables set for reproducibility.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c3e3a-1b16-4758-a989-b5dea30c9b0b",
   "metadata": {},
   "source": [
    "**<font size = 4> <font color = 'red'> READ IN MATCHUP DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52de31-4358-47b1-9f3a-91d0cb9045e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_series = nba_series = pd.read_csv(\"TEAM_MATCHUP_DATA_CLUSTER.csv\") # updated data set with CLUSTERING PROPORTIONS (CHECK BOX)\n",
    "\n",
    "nba_series['SEASON_YEAR'] = nba_series['SEASON'].str.split('-').str[0].astype(int)\n",
    "nba_series['SEASON'] = (nba_series['SEASON_YEAR'] + 1).astype(int)\n",
    "nba_series = nba_series.drop(columns=['SEASON_YEAR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d613767-78a4-4031-aa4f-99cc7950c8f8",
   "metadata": {},
   "source": [
    "**<font size = 4> <font color = 'red'> DATA CLEANING PT.1 (RANDOMIZING AND SHUFFLING)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d3f70-a7dc-46e1-ac72-775e92859658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are not needed\n",
    "nba_series = nba_series.drop(columns = ['SERIES_ID', 'SEASON_ID', 'TEAM_1_ID', 'TEAM_2_ID', 'CLUSTER_TEAM_1', 'CLUSTER_TEAM_2'])\n",
    "\n",
    "# Create a mask to flip half of the rows\n",
    "flip_mask = np.random.rand(len(nba_series)) < 0.5\n",
    "\n",
    "# Columns to swap\n",
    "team1_stat_cols = [col for col in nba_series.columns if '_TEAM_1' in col]\n",
    "team2_stat_cols = [col.replace('_TEAM_1', '_TEAM_2') for col in team1_stat_cols]\n",
    "\n",
    "# Include team name columns for flipping\n",
    "stat_swap_cols = team1_stat_cols + team2_stat_cols + ['TEAM_1', 'TEAM_2']\n",
    "\n",
    "# Create deep copies of swapped and non-swapped rows\n",
    "swapped = nba_series.loc[flip_mask].copy()\n",
    "not_swapped = nba_series.loc[~flip_mask].copy()\n",
    "\n",
    "# Flip stats\n",
    "swapped[team1_stat_cols] = nba_series.loc[flip_mask, team2_stat_cols].values\n",
    "swapped[team2_stat_cols] = nba_series.loc[flip_mask, team1_stat_cols].values\n",
    "\n",
    "# Flip team names\n",
    "swapped['TEAM_1'] = nba_series.loc[flip_mask, 'TEAM_2'].values\n",
    "swapped['TEAM_2'] = nba_series.loc[flip_mask, 'TEAM_1'].values\n",
    "\n",
    "# Recalculate TEAM_1_W based on new TEAM_1 vs SERIES_WINNER\n",
    "swapped['TEAM_1_W'] = (swapped['SERIES_WINNER'] == swapped['TEAM_1']).astype(int)\n",
    "not_swapped['TEAM_1_W'] = (not_swapped['SERIES_WINNER'] == not_swapped['TEAM_1']).astype(int)\n",
    "\n",
    "# Combine flipped and unflipped\n",
    "nba_series_balanced = pd.concat([swapped, not_swapped], ignore_index=True)\n",
    "\n",
    "# Optional: Shuffle the final DataFrame\n",
    "nba_series_balanced = nba_series_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# test_data_preserved is created for displaying results later on\n",
    "test_data_preserved = nba_series_balanced[['SEASON', 'TEAM_1', 'TEAM_2', 'SERIES_WINNER']]\n",
    "test_data_preserved = test_data_preserved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8bb5a-ec41-496e-a964-bd4961fdefdb",
   "metadata": {},
   "source": [
    "**<font size = 4> <font color = 'red'> DATA CLEANING PT.2 (DIFFERENCE IN STATS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9b11f7-5dfb-4a35-bc75-36a19c873d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically extract stat bases by checking for matching suffixes\n",
    "diff_df = pd.DataFrame()\n",
    "\n",
    "# Grab all columns ending in _TEAM_1\n",
    "team1_cols = [col for col in nba_series_balanced.columns if col.endswith('_TEAM_1')]\n",
    "\n",
    "for col1 in team1_cols:\n",
    "    # Get the base stat name (e.g., 'AST', 'FG_PCT')\n",
    "    stat_base = col1.replace('_TEAM_1', '')\n",
    "    col2 = f'{stat_base}_TEAM_2'\n",
    "    \n",
    "    # Only compute diff if TEAM_2 version exists\n",
    "    if col2 in nba_series_balanced.columns:\n",
    "        diff_df[f'{stat_base}_DIFF'] = nba_series_balanced[col1] - nba_series_balanced[col2]\n",
    "\n",
    "# Add label and season columns\n",
    "diff_df['TEAM_1_W'] = nba_series_balanced['TEAM_1_W']\n",
    "diff_df['SEASON'] = nba_series_balanced['SEASON']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc69f51-60b1-4c83-b817-b473de8e87b0",
   "metadata": {},
   "source": [
    "**<font size = 4> <font color = 'red'> TABNET NEURAL NETWORK WITH TEMPORAL SPLITS AND OPTUNA HYPERTUNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83171091-4466-430b-93e4-3d2428ec8d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Ensure save directory exists\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "years = np.arange(2020, 2025)\n",
    "\n",
    "def objective_tabnet(trial):\n",
    "    \n",
    "    n_d = trial.suggest_int(\"n_d\", 8, 64, step=8)\n",
    "    n_a = trial.suggest_int(\"n_a\", 8, 64, step=8)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 3, 10)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1.0, 2.0)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 0.00001, 0.01, log=True)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.01, 0.4)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-3, 2e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", ['sparsemax', 'entmax'])\n",
    "    \n",
    "\n",
    "    '''\n",
    "    n_d = trial.suggest_int(\"n_d\", 40, 56, step=4)\n",
    "    n_a = trial.suggest_int(\"n_a\", 40, 56, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 6, 10)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1.0, 1.2)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-5, 1e-3, log=True)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.3, 0.4)\n",
    "    lr = trial.suggest_float(\"lr\", 0.001, 0.003, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-5, log=True)\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", ['sparsemax', 'entmax'])\n",
    "    '''\n",
    "\n",
    "    # Store predictions and true labels for global metrics\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_prob = []\n",
    "\n",
    "    for year in years:\n",
    "        train_data = diff_df[diff_df['SEASON'] < year]\n",
    "        test_data = diff_df[diff_df['SEASON'] == year]\n",
    "\n",
    "        if train_data.empty or test_data.empty:\n",
    "            continue\n",
    "\n",
    "        X_train = train_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "        y_train = train_data['TEAM_1_W']\n",
    "        X_test = test_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "        y_test = test_data['TEAM_1_W']\n",
    "\n",
    "        smote = SMOTE(random_state=10)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        clf = TabNetClassifier(\n",
    "            n_d=n_d, n_a=n_a, n_steps=n_steps,\n",
    "            gamma=gamma, lambda_sparse=lambda_sparse,\n",
    "            momentum=momentum, mask_type=mask_type,\n",
    "            optimizer_params={\"lr\": lr, \"weight_decay\": weight_decay},\n",
    "            seed=342221, verbose=0, device_name='cpu'\n",
    "        )\n",
    "\n",
    "        clf.fit(\n",
    "            X_train_resampled.values, y_train_resampled.values,\n",
    "            eval_set=[(X_test.values, y_test.values)],\n",
    "            eval_metric=['auc'],\n",
    "            max_epochs=200, patience=20,\n",
    "            batch_size=64, virtual_batch_size=32\n",
    "        )\n",
    "\n",
    "        y_probs = clf.predict_proba(X_test.values)[:, 1]\n",
    "        y_pred = (y_probs >= 0.5).astype(int)\n",
    "\n",
    "        #preds_label = clf.predict(X_test.values)\n",
    "\n",
    "        # Collect for global metrics\n",
    "        all_y_true.extend(y_test.values)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        all_y_prob.extend(y_probs)\n",
    "\n",
    "    if len(all_y_true) == 0:\n",
    "        # Skip trial if no data\n",
    "        return 0.0\n",
    "\n",
    "    # Compute global metrics\n",
    "    global_auc = roc_auc_score(all_y_true, all_y_prob)\n",
    "    global_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    global_f1 = f1_score(all_y_true, all_y_pred)\n",
    "\n",
    "    print(f\"Trial {trial.number}: Global AUC = {global_auc:.4f}, Accuracy = {global_accuracy:.4f}, F1 = {global_f1:.4f}\")\n",
    "\n",
    "    \n",
    "    # ✅ Save models with high AUC\n",
    "    if global_auc >= 0.90:\n",
    "        filename = f\"tabnet_trial{trial.number}_auc{global_auc:.4f}.zip\"\n",
    "        filepath = os.path.join(\"saved_models\", filename)\n",
    "        clf.save_model(filepath)\n",
    "        print(f\"✅ Saved model for Trial {trial.number} → {filename}\")\n",
    "    \n",
    "\n",
    "    return global_auc\n",
    "\n",
    "# Run the Optuna study\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=342221))\n",
    "study.optimize(objective_tabnet, n_trials=50)\n",
    "\n",
    "# Print best results\n",
    "print(\"Best AUC:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066b9d45-d6be-4908-9a5e-57a4fd942f72",
   "metadata": {},
   "source": [
    "**<font size = 4> <font color = 'red'> TABNET THRESHOLD TUNING WITH BEST MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61164767-3ced-4b15-b966-9db1bf77373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, f1_score,\n",
    "    confusion_matrix, roc_curve, auc\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Define rolling years\n",
    "years = np.arange(2020, 2025)\n",
    "\n",
    "# Set range for threshold to fine tune it (i.e thresholds from 0.4 to 0.6 with a step of 0.05)\n",
    "thresholds = thresholds = np.arange(0.4, 0.6, 0.05)\n",
    "\n",
    "# Best found parameters from Optuna\n",
    "\n",
    "# 84% accuracy set (2020-2025 test), 0.895 AUC, threshold = 0.5, seed = 10\n",
    "best_params = {\n",
    "    'n_d': 48,\n",
    "    'n_a': 48,\n",
    "    'n_steps': 8,\n",
    "    'gamma': 1.0950455922432034,\n",
    "    'lambda_sparse': 0.000365814411562923,\n",
    "    'momentum': 0.3675391603570311,\n",
    "    'mask_type': 'sparsemax'\n",
    "}\n",
    "\n",
    "optimizer_params = {\n",
    "    'lr': 0.002071649487926403,\n",
    "    'weight_decay': 4.2583833531711615e-06\n",
    "}\n",
    "\n",
    "# Store ROC values\n",
    "all_fpr = []\n",
    "all_tpr = []\n",
    "all_auc = []\n",
    "\n",
    "threshold_results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"\\n--- Threshold: {threshold:.4f} ---\")\n",
    "    store_acc = []\n",
    "    store_f1 = []\n",
    "    total_y_true = []\n",
    "    total_y_probs = []\n",
    "\n",
    "    for year in years:\n",
    "        train_data = diff_df[diff_df['SEASON'] < year]\n",
    "        test_data = diff_df[diff_df['SEASON'] == year]\n",
    "\n",
    "        display_test = test_data_preserved[test_data_preserved['SEASON'] == year]\n",
    "\n",
    "        if train_data.empty or test_data.empty:\n",
    "            continue\n",
    "\n",
    "        X_train = train_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "        y_train = train_data['TEAM_1_W']\n",
    "        X_test = test_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "        y_test = test_data['TEAM_1_W']\n",
    "\n",
    "        smote = SMOTE(random_state=10)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        clf = TabNetClassifier(\n",
    "            **best_params, optimizer_params = optimizer_params, verbose=0, seed=10, device_name='cpu'\n",
    "        )\n",
    "\n",
    "        clf.fit(\n",
    "            X_train_resampled.values, y_train_resampled.values,\n",
    "            eval_set=[(X_test.values, y_test.values)],\n",
    "            eval_metric=['auc'],\n",
    "            max_epochs=200, patience=20,\n",
    "            batch_size=64, virtual_batch_size=32\n",
    "        )\n",
    "\n",
    "        y_probs = clf.predict_proba(X_test.values)[:, 1]\n",
    "        y_pred = (y_probs >= threshold).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        store_acc.append(acc)\n",
    "        store_f1.append(f1)\n",
    "\n",
    "        print(f\"Season {year} — Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "        display_test['TEAM_1_W'] = y_test\n",
    "        display_test['PRED_TEAM_1_W'] = y_pred\n",
    "        display_test['PRED_PROB'] = y_probs\n",
    "\n",
    "        print(display_test)\n",
    "        \n",
    "        total_y_true.extend(y_test.values)\n",
    "        total_y_probs.extend(y_probs)\n",
    "\n",
    "    # ROC curve calculation for this threshold\n",
    "    fpr, tpr, _ = roc_curve(total_y_true, total_y_probs)\n",
    "    all_fpr.append(fpr)\n",
    "    all_tpr.append(tpr)\n",
    "    all_auc.append(auc(fpr, tpr))\n",
    "\n",
    "    threshold_results.append({\n",
    "        \"threshold\": threshold,\n",
    "        \"auc\": auc(fpr, tpr),\n",
    "        \"accuracy\": np.mean(store_acc),\n",
    "        \"f1\": np.mean(store_f1)\n",
    "    })\n",
    "\n",
    "    print(f\"Threshold {threshold}: AUC = {np.mean(auc(fpr, tpr)):.4f}, Accuracy = {np.mean(store_acc):.4f}, F1 = {np.mean(store_f1):.4f}\")\n",
    "\n",
    "# Final ROC curve plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i, thr in enumerate(thresholds):\n",
    "    plt.plot(all_fpr[i], all_tpr[i], label=f\"Threshold {thr:.2f} (AUC = {all_auc[i]:.2f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Chance\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves for Various Thresholds\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56de54-5ccc-4f42-81f5-7405b241d4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NBACluster)",
   "language": "python",
   "name": "nbacluster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
