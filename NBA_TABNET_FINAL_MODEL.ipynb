{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ead2d3e-1534-4e5f-befb-7c384a9abdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86cfefc4-a9d3-4398-8ff7-8e6056f2a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds and environment variables set for reproducibility.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set a fixed seed value\n",
    "seed_value = 10\n",
    "\n",
    "# 1. Set PYTHONHASHSEED environment variable for reproducibility in hashing\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# 2. Set the seed for Python's built-in random module\n",
    "random.seed(10)\n",
    "\n",
    "# 3. Set the seed for NumPy\n",
    "np.random.seed(10)\n",
    "\n",
    "# 4. Set the seed for PyTorch\n",
    "torch.manual_seed(seed_value)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "# 5. Force PyTorch to use deterministic algorithms (may impact performance)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "# 6. Optionally limit the number of threads used by OMP and MKL (helps reduce non-determinism)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "print(\"Seeds and environment variables set for reproducibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a1c266-f42d-48d1-9c4f-fc78f84224af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_series = nba_series = pd.read_csv(\"TEAM_MATCHUP_DATA_CLUSTER.csv\") # updated data set with CLUSTERING PROPORTIONS (CHECK BOX)\n",
    "\n",
    "nba_series['SEASON_YEAR'] = nba_series['SEASON'].str.split('-').str[0].astype(int)\n",
    "nba_series['SEASON'] = (nba_series['SEASON_YEAR'] + 1).astype(int)\n",
    "nba_series = nba_series.drop(columns=['SEASON_YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82626607-6def-4a6c-8ada-d0a5e3a21c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarvesh\\AppData\\Local\\Temp\\ipykernel_28052\\651144542.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  swapped['TEAM_1_W'] = (swapped['SERIES_WINNER'] == swapped['TEAM_1']).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that are not needed\n",
    "nba_series = nba_series.drop(columns = ['SERIES_ID', 'SEASON_ID', 'TEAM_1_ID', 'TEAM_2_ID', 'CLUSTER_TEAM_1', 'CLUSTER_TEAM_2'])\n",
    "\n",
    "# Create a mask to flip half of the rows\n",
    "flip_mask = np.random.rand(len(nba_series)) < 0.5\n",
    "\n",
    "# Columns to swap\n",
    "team1_stat_cols = [col for col in nba_series.columns if '_TEAM_1' in col]\n",
    "team2_stat_cols = [col.replace('_TEAM_1', '_TEAM_2') for col in team1_stat_cols]\n",
    "\n",
    "# Include team name columns for flipping\n",
    "stat_swap_cols = team1_stat_cols + team2_stat_cols + ['TEAM_1', 'TEAM_2']\n",
    "\n",
    "# Create deep copies of swapped and non-swapped rows\n",
    "swapped = nba_series.loc[flip_mask].copy()\n",
    "not_swapped = nba_series.loc[~flip_mask].copy()\n",
    "\n",
    "# Flip stats\n",
    "swapped[team1_stat_cols] = nba_series.loc[flip_mask, team2_stat_cols].values\n",
    "swapped[team2_stat_cols] = nba_series.loc[flip_mask, team1_stat_cols].values\n",
    "\n",
    "# Flip team names\n",
    "swapped['TEAM_1'] = nba_series.loc[flip_mask, 'TEAM_2'].values\n",
    "swapped['TEAM_2'] = nba_series.loc[flip_mask, 'TEAM_1'].values\n",
    "\n",
    "# Recalculate TEAM_1_W based on new TEAM_1 vs SERIES_WINNER\n",
    "swapped['TEAM_1_W'] = (swapped['SERIES_WINNER'] == swapped['TEAM_1']).astype(int)\n",
    "not_swapped['TEAM_1_W'] = (not_swapped['SERIES_WINNER'] == not_swapped['TEAM_1']).astype(int)\n",
    "\n",
    "# Combine flipped and unflipped\n",
    "nba_series_balanced = pd.concat([swapped, not_swapped], ignore_index=True)\n",
    "\n",
    "# Optional: Shuffle the final DataFrame\n",
    "nba_series_balanced = nba_series_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# test_data_preserved is created for displaying results later on\n",
    "test_data_preserved = nba_series_balanced[['SEASON', 'TEAM_1', 'TEAM_2', 'SERIES_WINNER']]\n",
    "test_data_preserved = test_data_preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e3e28e-d2dd-461c-bb48-01dc6d7304b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically extract stat bases by checking for matching suffixes\n",
    "diff_df = pd.DataFrame()\n",
    "\n",
    "# Grab all columns ending in _TEAM_1\n",
    "team1_cols = [col for col in nba_series_balanced.columns if col.endswith('_TEAM_1')]\n",
    "\n",
    "for col1 in team1_cols:\n",
    "    # Get the base stat name (e.g., 'AST', 'FG_PCT')\n",
    "    stat_base = col1.replace('_TEAM_1', '')\n",
    "    col2 = f'{stat_base}_TEAM_2'\n",
    "    \n",
    "    # Only compute diff if TEAM_2 version exists\n",
    "    if col2 in nba_series_balanced.columns:\n",
    "        diff_df[f'{stat_base}_DIFF'] = nba_series_balanced[col1] - nba_series_balanced[col2]\n",
    "\n",
    "# Add label and season columns\n",
    "diff_df['TEAM_1_W'] = nba_series_balanced['TEAM_1_W']\n",
    "diff_df['SEASON'] = nba_series_balanced['SEASON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502659a-0ee6-4641-b5a8-a37ee86aed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÜ Evaluating year: 2020\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 26 and best_val_0_auc = 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.92857\n",
      "AUC: 0.8750 | Accuracy: 0.9333 | F1: 0.9333\n",
      "Binary Cross-Entropy Loss: 0.4935\n",
      "Confusion Matrix:\n",
      "[[7 0]\n",
      " [1 7]]\n",
      "\n",
      "üìÜ Evaluating year: 2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.88889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.7963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9444 | Accuracy: 0.8667 | F1: 0.8333\n",
      "Binary Cross-Entropy Loss: 0.4931\n",
      "Confusion Matrix:\n",
      "[[8 1]\n",
      " [1 5]]\n",
      "\n",
      "üìÜ Evaluating year: 2022\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, log_loss\n",
    "import numpy as np\n",
    "\n",
    "# Tracking\n",
    "all_y_true = []\n",
    "all_y_prob_blended = []\n",
    "all_y_pred_blended = []\n",
    "\n",
    "# Per-year metrics\n",
    "yearly_metrics = []\n",
    "\n",
    "years = np.arange(2020, 2025)\n",
    "\n",
    "# 84% accuracy set (2020-2025 test), 0.883 AUC, threshold = 0.5, seed = 8 (fit, optuna)\n",
    "params_a = {\n",
    "    'n_d': 56,\n",
    "    'n_a': 64,\n",
    "    'n_steps': 6,\n",
    "    'gamma': 1.3930814539055605,\n",
    "    'lambda_sparse': 0.0029833605183872134,\n",
    "    'momentum': 0.15891701764952307,\n",
    "    'mask_type': 'entmax'\n",
    "}\n",
    "\n",
    "opt_params_a = {\n",
    "    'lr': 0.0076661428463103455,\n",
    "    'weight_decay': 2.501056095511525e-05\n",
    "}\n",
    "\n",
    "# 85% accuracy set (2020-2025 test), 0.89 AUC, threshold = 0.51, seed = 10 (fit, optuna)\n",
    "params_b = {\n",
    "    'n_d': 48,\n",
    "    'n_a': 48,\n",
    "    'n_steps': 8,\n",
    "    'gamma': 1.0950455922432034,\n",
    "    'lambda_sparse': 0.000365814411562923,\n",
    "    'momentum': 0.3675391603570311,\n",
    "    'mask_type': 'sparsemax'\n",
    "}\n",
    "\n",
    "opt_params_b = {\n",
    "    'lr': 0.002071649487926403,\n",
    "    'weight_decay': 4.2583833531711615e-06\n",
    "}\n",
    "\n",
    "# 79% accuracy set (2005-2005 test), 0.869 AUC, threshold = 0.5, seed = 5 (fit, optuna) \n",
    "params_c = {\n",
    "    'n_d': 48,\n",
    "    'n_a': 32,\n",
    "    'n_steps': 5,\n",
    "    'gamma': 1.1885687695822824,\n",
    "    'lambda_sparse': 0.0019929526182699384,\n",
    "    'momentum': 0.25773242436863386,\n",
    "    'mask_type': 'entmax'\n",
    "}\n",
    "\n",
    "opt_params_c = {\n",
    "    'lr': 0.01601995480535204,\n",
    "    'weight_decay': 0.00015417059849810502,\n",
    "}\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    print(f\"\\nüìÜ Evaluating year: {year}\")\n",
    "    train_data = diff_df[diff_df['SEASON'] < year]\n",
    "    test_data = diff_df[diff_df['SEASON'] == year]\n",
    "    \n",
    "    if train_data.empty or test_data.empty:\n",
    "        continue\n",
    "\n",
    "    X_train = train_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "    y_train = train_data['TEAM_1_W']\n",
    "    X_test = test_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "    y_test = test_data['TEAM_1_W']\n",
    "\n",
    "    smote = SMOTE(random_state=10)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # -------- Model A --------\n",
    "    model_a = TabNetClassifier(\n",
    "        **params_a,\n",
    "        optimizer_params=opt_params_a,\n",
    "        seed=8,\n",
    "        device_name='cpu',\n",
    "        verbose=0\n",
    "    )\n",
    "    model_a.fit(\n",
    "        X_train_resampled.values, y_train_resampled.values,\n",
    "        eval_set=[(X_test.values, y_test.values)],\n",
    "        eval_metric=['auc'],\n",
    "        max_epochs=200, patience=20,\n",
    "        batch_size=64, virtual_batch_size=32\n",
    "    )\n",
    "    probs_a = model_a.predict_proba(X_test.values)[:, 1]\n",
    "\n",
    "    # -------- Model B --------\n",
    "    model_b = TabNetClassifier(\n",
    "        **params_b,\n",
    "        optimizer_params=opt_params_b,\n",
    "        seed=10,\n",
    "        device_name='cpu',\n",
    "        verbose=0\n",
    "    )\n",
    "    model_b.fit(\n",
    "        X_train_resampled.values, y_train_resampled.values,\n",
    "        eval_set=[(X_test.values, y_test.values)],\n",
    "        eval_metric=['auc'],\n",
    "        max_epochs=200, patience=20,\n",
    "        batch_size=64, virtual_batch_size=32\n",
    "    )\n",
    "    probs_b = model_b.predict_proba(X_test.values)[:, 1]\n",
    "\n",
    "    '''\n",
    "    # -------- Model C --------\n",
    "    model_c = TabNetClassifier(\n",
    "        **params_c,\n",
    "        optimizer_params=opt_params_c,\n",
    "        seed=5,\n",
    "        device_name='cpu',\n",
    "        verbose=0\n",
    "    )\n",
    "    model_c.fit(\n",
    "        X_train_resampled.values, y_train_resampled.values,\n",
    "        eval_set=[(X_test.values, y_test.values)],\n",
    "        eval_metric=['auc'],\n",
    "        max_epochs=200, patience=20,\n",
    "        batch_size=64, virtual_batch_size=32\n",
    "    )\n",
    "    probs_c = model_c.predict_proba(X_test.values)[:, 1]\n",
    "    '''\n",
    "\n",
    "    # -------- Blend Predictions --------\n",
    "    blended_probs = (probs_a + probs_b) / 2\n",
    "    blended_preds = (blended_probs >= 0.505).astype(int)\n",
    "\n",
    "    bce_loss = log_loss(y_test, blended_probs)\n",
    "\n",
    "    # Metrics for this year\n",
    "    auc = roc_auc_score(y_test, blended_probs)\n",
    "    acc = accuracy_score(y_test, blended_preds)\n",
    "    f1 = f1_score(y_test, blended_preds)\n",
    "    cm = confusion_matrix(y_test, blended_preds)\n",
    "\n",
    "    print(f\"AUC: {auc:.4f} | Accuracy: {acc:.4f} | F1: {f1:.4f}\")\n",
    "    print(f\"Binary Cross-Entropy Loss: {bce_loss:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    yearly_metrics.append({\n",
    "        \"year\": year,\n",
    "        \"auc\": auc,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": cm\n",
    "    })\n",
    "\n",
    "    # Global tracking\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_prob_blended.extend(blended_probs)\n",
    "    all_y_pred_blended.extend(blended_preds)\n",
    "\n",
    "# ------ Overall Metrics ------\n",
    "overall_auc = roc_auc_score(all_y_true, all_y_prob_blended)\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred_blended)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred_blended)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred_blended)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred_blended)\n",
    "overall_bce_loss = log_loss(all_y_true, all_y_prob_blended)\n",
    "\n",
    "print(f\"\\nüîÅ Overall Blended Model Performance:\")\n",
    "print(f\"AUC: {overall_auc:.4f}, Accuracy: {overall_acc:.4f}, F1: {overall_f1:.4f}, Precision: {overall_prec:.4f}, Recall: {overall_rec:.4f}\")\n",
    "print(f\"Overall Binary Cross-Entropy Loss: {overall_bce_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32323e-8be3-413e-9381-3ac2d57cefab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NBACluster)",
   "language": "python",
   "name": "nbacluster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
