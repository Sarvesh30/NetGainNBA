{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ead2d3e-1534-4e5f-befb-7c384a9abdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86cfefc4-a9d3-4398-8ff7-8e6056f2a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds and environment variables set for reproducibility.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set a fixed seed value\n",
    "seed_value = 10\n",
    "\n",
    "# 1. Set PYTHONHASHSEED environment variable for reproducibility in hashing\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "# 2. Set the seed for Python's built-in random module\n",
    "random.seed(10)\n",
    "\n",
    "# 3. Set the seed for NumPy\n",
    "np.random.seed(10)\n",
    "\n",
    "# 4. Set the seed for PyTorch\n",
    "torch.manual_seed(seed_value)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "# 5. Force PyTorch to use deterministic algorithms (may impact performance)\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "\n",
    "# 6. Optionally limit the number of threads used by OMP and MKL (helps reduce non-determinism)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "print(\"Seeds and environment variables set for reproducibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a1c266-f42d-48d1-9c4f-fc78f84224af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_series = nba_series = pd.read_csv(\"TEAM_MATCHUP_DATA_CLUSTER.csv\") # updated data set with CLUSTERING PROPORTIONS (CHECK BOX)\n",
    "\n",
    "nba_series['SEASON_YEAR'] = nba_series['SEASON'].str.split('-').str[0].astype(int)\n",
    "nba_series['SEASON'] = (nba_series['SEASON_YEAR'] + 1).astype(int)\n",
    "nba_series = nba_series.drop(columns=['SEASON_YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82626607-6def-4a6c-8ada-d0a5e3a21c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sarvesh\\AppData\\Local\\Temp\\ipykernel_20820\\651144542.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  swapped['TEAM_1_W'] = (swapped['SERIES_WINNER'] == swapped['TEAM_1']).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that are not needed\n",
    "nba_series = nba_series.drop(columns = ['SERIES_ID', 'SEASON_ID', 'TEAM_1_ID', 'TEAM_2_ID', 'CLUSTER_TEAM_1', 'CLUSTER_TEAM_2'])\n",
    "\n",
    "# Create a mask to flip half of the rows\n",
    "flip_mask = np.random.rand(len(nba_series)) < 0.5\n",
    "\n",
    "# Columns to swap\n",
    "team1_stat_cols = [col for col in nba_series.columns if '_TEAM_1' in col]\n",
    "team2_stat_cols = [col.replace('_TEAM_1', '_TEAM_2') for col in team1_stat_cols]\n",
    "\n",
    "# Include team name columns for flipping\n",
    "stat_swap_cols = team1_stat_cols + team2_stat_cols + ['TEAM_1', 'TEAM_2']\n",
    "\n",
    "# Create deep copies of swapped and non-swapped rows\n",
    "swapped = nba_series.loc[flip_mask].copy()\n",
    "not_swapped = nba_series.loc[~flip_mask].copy()\n",
    "\n",
    "# Flip stats\n",
    "swapped[team1_stat_cols] = nba_series.loc[flip_mask, team2_stat_cols].values\n",
    "swapped[team2_stat_cols] = nba_series.loc[flip_mask, team1_stat_cols].values\n",
    "\n",
    "# Flip team names\n",
    "swapped['TEAM_1'] = nba_series.loc[flip_mask, 'TEAM_2'].values\n",
    "swapped['TEAM_2'] = nba_series.loc[flip_mask, 'TEAM_1'].values\n",
    "\n",
    "# Recalculate TEAM_1_W based on new TEAM_1 vs SERIES_WINNER\n",
    "swapped['TEAM_1_W'] = (swapped['SERIES_WINNER'] == swapped['TEAM_1']).astype(int)\n",
    "not_swapped['TEAM_1_W'] = (not_swapped['SERIES_WINNER'] == not_swapped['TEAM_1']).astype(int)\n",
    "\n",
    "# Combine flipped and unflipped\n",
    "nba_series_balanced = pd.concat([swapped, not_swapped], ignore_index=True)\n",
    "\n",
    "# Optional: Shuffle the final DataFrame\n",
    "nba_series_balanced = nba_series_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# test_data_preserved is created for displaying results later on\n",
    "test_data_preserved = nba_series_balanced[['SEASON', 'TEAM_1', 'TEAM_2', 'SERIES_WINNER']]\n",
    "test_data_preserved = test_data_preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e3e28e-d2dd-461c-bb48-01dc6d7304b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically extract stat bases by checking for matching suffixes\n",
    "diff_df = pd.DataFrame()\n",
    "\n",
    "# Grab all columns ending in _TEAM_1\n",
    "team1_cols = [col for col in nba_series_balanced.columns if col.endswith('_TEAM_1')]\n",
    "\n",
    "for col1 in team1_cols:\n",
    "    # Get the base stat name (e.g., 'AST', 'FG_PCT')\n",
    "    stat_base = col1.replace('_TEAM_1', '')\n",
    "    col2 = f'{stat_base}_TEAM_2'\n",
    "    \n",
    "    # Only compute diff if TEAM_2 version exists\n",
    "    if col2 in nba_series_balanced.columns:\n",
    "        diff_df[f'{stat_base}_DIFF'] = nba_series_balanced[col1] - nba_series_balanced[col2]\n",
    "\n",
    "# Add label and season columns\n",
    "diff_df['TEAM_1_W'] = nba_series_balanced['TEAM_1_W']\n",
    "diff_df['SEASON'] = nba_series_balanced['SEASON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfd896b9-1163-4321-998e-389dd371dbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:15:36,227] A new study created in memory with name: no-name-40f6214c-6325-41d6-90fb-5fadeabd72c2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.98214\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.75926\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_auc = 0.81481\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.73214\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:17:28,984] Trial 0 finished with value: 0.6714285714285714 and parameters: {'n_d': 56, 'n_a': 64, 'n_steps': 9, 'gamma': 1.5308556915555989, 'lambda_sparse': 4.990970282009197e-05, 'momentum': 0.01444553366819766, 'lr': 0.0036312223666535117, 'weight_decay': 4.068229457500928e-05, 'mask_type': 'sparsemax'}. Best is trial 0 with value: 0.6714285714285714.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Global AUC = 0.6714, Accuracy = 0.6267, F1 = 0.6500\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.73214\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_0_auc = 0.77778\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_auc = 0.96296\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_auc = 0.75\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:19:10,061] Trial 1 finished with value: 0.687857142857143 and parameters: {'n_d': 40, 'n_a': 40, 'n_steps': 9, 'gamma': 1.7123745740820913, 'lambda_sparse': 0.0007228468425177478, 'momentum': 0.17617579048571497, 'lr': 0.002377361812957646, 'weight_decay': 0.007859971382309462, 'mask_type': 'sparsemax'}. Best is trial 1 with value: 0.687857142857143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: Global AUC = 0.6879, Accuracy = 0.6533, F1 = 0.6579\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.58929\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 36 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.98148\n",
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 39 and best_val_0_auc = 0.55357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:20:13,011] Trial 2 finished with value: 0.7121428571428571 and parameters: {'n_d': 8, 'n_a': 64, 'n_steps': 4, 'gamma': 1.3221307932041793, 'lambda_sparse': 1.6324073226031766e-05, 'momentum': 0.09766027619753771, 'lr': 0.003251852450379615, 'weight_decay': 0.0038422004587685657, 'mask_type': 'entmax'}. Best is trial 2 with value: 0.7121428571428571.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 53 and best_val_0_auc = 0.82\n",
      "Trial 2: Global AUC = 0.7121, Accuracy = 0.6933, F1 = 0.7160\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.82143\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.87037\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.71429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:21:12,836] Trial 3 finished with value: 0.7235714285714285 and parameters: {'n_d': 8, 'n_a': 24, 'n_steps': 6, 'gamma': 1.76416013136596, 'lambda_sparse': 0.006552571068132416, 'momentum': 0.1346790206221408, 'lr': 0.0036531218718936728, 'weight_decay': 1.203879353465923e-05, 'mask_type': 'sparsemax'}. Best is trial 3 with value: 0.7235714285714285.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_val_0_auc = 0.98\n",
      "Trial 3: Global AUC = 0.7236, Accuracy = 0.6400, F1 = 0.6582\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.81481\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.67857\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:22:18,439] Trial 4 finished with value: 0.7842857142857143 and parameters: {'n_d': 8, 'n_a': 40, 'n_steps': 9, 'gamma': 1.0320081564257968, 'lambda_sparse': 0.00023245744835443608, 'momentum': 0.31816729112193143, 'lr': 0.019328302931741426, 'weight_decay': 0.00021669963210163259, 'mask_type': 'entmax'}. Best is trial 4 with value: 0.7842857142857143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4: Global AUC = 0.7843, Accuracy = 0.6933, F1 = 0.7089\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.89286\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.85714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:22:48,254] Trial 5 finished with value: 0.7728571428571429 and parameters: {'n_d': 16, 'n_a': 48, 'n_steps': 4, 'gamma': 1.1509701076574963, 'lambda_sparse': 0.0004059129621815389, 'momentum': 0.04915084974757424, 'lr': 0.00893838488977817, 'weight_decay': 0.005735934161738023, 'mask_type': 'sparsemax'}. Best is trial 4 with value: 0.7842857142857143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.9\n",
      "Trial 5: Global AUC = 0.7729, Accuracy = 0.7200, F1 = 0.7342\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.75926\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.81481\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:23:57,705] Trial 6 finished with value: 0.725 and parameters: {'n_d': 40, 'n_a': 48, 'n_steps': 7, 'gamma': 1.4708925816438496, 'lambda_sparse': 1.0632046240481986e-05, 'momentum': 0.03647959739049399, 'lr': 0.0036788235311049832, 'weight_decay': 5.320770457754584e-05, 'mask_type': 'entmax'}. Best is trial 4 with value: 0.7842857142857143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6: Global AUC = 0.7250, Accuracy = 0.6933, F1 = 0.7013\n",
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 29 and best_val_0_auc = 0.80357\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 26 and best_val_0_auc = 0.90741\n",
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 48 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.71429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:25:03,736] Trial 7 finished with value: 0.7892857142857144 and parameters: {'n_d': 40, 'n_a': 48, 'n_steps': 5, 'gamma': 1.4043954647747654, 'lambda_sparse': 0.002939999533442052, 'momentum': 0.23898083698176592, 'lr': 0.008302290288792287, 'weight_decay': 0.0001102374063661712, 'mask_type': 'sparsemax'}. Best is trial 7 with value: 0.7892857142857144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_auc = 0.84\n",
      "Trial 7: Global AUC = 0.7893, Accuracy = 0.7333, F1 = 0.7500\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.80357\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.73214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:25:55,271] Trial 8 finished with value: 0.7507142857142857 and parameters: {'n_d': 56, 'n_a': 16, 'n_steps': 5, 'gamma': 1.475804022063774, 'lambda_sparse': 0.0003025613809869108, 'momentum': 0.24699369097993717, 'lr': 0.011626787906753693, 'weight_decay': 0.00012909081826983457, 'mask_type': 'sparsemax'}. Best is trial 7 with value: 0.7892857142857144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.86\n",
      "Trial 8: Global AUC = 0.7507, Accuracy = 0.7200, F1 = 0.7200\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 1.0\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.81481\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.76786\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:27:03,649] Trial 9 finished with value: 0.7392857142857143 and parameters: {'n_d': 16, 'n_a': 40, 'n_steps': 7, 'gamma': 1.7634046146371465, 'lambda_sparse': 0.0026298986106230524, 'momentum': 0.126463828995592, 'lr': 0.0015137099106642764, 'weight_decay': 0.0003480099464890292, 'mask_type': 'entmax'}. Best is trial 7 with value: 0.7892857142857144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9: Global AUC = 0.7393, Accuracy = 0.6667, F1 = 0.6988\n",
      "\n",
      "Early stopping occurred at epoch 82 with best_epoch = 62 and best_val_0_auc = 0.92857\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.67857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:27:46,505] Trial 10 finished with value: 0.77 and parameters: {'n_d': 32, 'n_a': 24, 'n_steps': 3, 'gamma': 1.9735325876335459, 'lambda_sparse': 0.0017517052456651192, 'momentum': 0.39009455918563246, 'lr': 0.00767300325393085, 'weight_decay': 1.1004318714335798e-06, 'mask_type': 'sparsemax'}. Best is trial 7 with value: 0.7892857142857144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.86\n",
      "Trial 10: Global AUC = 0.7700, Accuracy = 0.6800, F1 = 0.6923\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.80357\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_auc = 0.87037\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.81481\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.66071\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:29:06,155] Trial 11 finished with value: 0.7242857142857143 and parameters: {'n_d': 32, 'n_a': 48, 'n_steps': 10, 'gamma': 1.005285317877912, 'lambda_sparse': 0.00012378200913771534, 'momentum': 0.2835851253036174, 'lr': 0.01999160874884308, 'weight_decay': 0.0006346321292047193, 'mask_type': 'entmax'}. Best is trial 7 with value: 0.7892857142857144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 11: Global AUC = 0.7243, Accuracy = 0.7067, F1 = 0.7442\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.82143\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.98148\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.92593\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.60714\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:30:02,513] Trial 12 finished with value: 0.7735714285714285 and parameters: {'n_d': 48, 'n_a': 32, 'n_steps': 8, 'gamma': 1.2061050191611402, 'lambda_sparse': 9.225061188223176e-05, 'momentum': 0.33177510103612345, 'lr': 0.01667871804954738, 'weight_decay': 0.0009377005903791851, 'mask_type': 'entmax'}. Best is trial 7 with value: 0.7892857142857144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 12: Global AUC = 0.7736, Accuracy = 0.6800, F1 = 0.6923\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 1.0\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.69643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:30:44,192] Trial 13 finished with value: 0.7414285714285714 and parameters: {'n_d': 24, 'n_a': 8, 'n_steps': 6, 'gamma': 1.0369867302035596, 'lambda_sparse': 0.006113064050389036, 'momentum': 0.22371930451249375, 'lr': 0.00652214297791766, 'weight_decay': 1.4719313885091695e-05, 'mask_type': 'entmax'}. Best is trial 7 with value: 0.7892857142857144.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.9\n",
      "Trial 13: Global AUC = 0.7414, Accuracy = 0.7067, F1 = 0.7179\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.89286\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_val_0_auc = 0.87037\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.69643\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:32:14,276] Trial 14 finished with value: 0.7907142857142857 and parameters: {'n_d': 64, 'n_a': 56, 'n_steps': 10, 'gamma': 1.350817325687668, 'lambda_sparse': 0.0011170639679267587, 'momentum': 0.3144093703350502, 'lr': 0.013500614423977172, 'weight_decay': 0.00022317055805078654, 'mask_type': 'sparsemax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14: Global AUC = 0.7907, Accuracy = 0.7200, F1 = 0.7273\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.67857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:33:07,096] Trial 15 finished with value: 0.7214285714285714 and parameters: {'n_d': 64, 'n_a': 56, 'n_steps': 5, 'gamma': 1.307153454887851, 'lambda_sparse': 0.0013904553417243943, 'momentum': 0.3646736164139113, 'lr': 0.0058683635255146836, 'weight_decay': 0.0013230063195550834, 'mask_type': 'sparsemax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.84\n",
      "Trial 15: Global AUC = 0.7214, Accuracy = 0.6933, F1 = 0.6933\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.89286\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 42 and best_val_0_auc = 0.96296\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:34:50,721] Trial 16 finished with value: 0.7528571428571429 and parameters: {'n_d': 64, 'n_a': 56, 'n_steps': 10, 'gamma': 1.5968771597594347, 'lambda_sparse': 0.003172446423698606, 'momentum': 0.2701595378355434, 'lr': 0.01242553895794396, 'weight_decay': 1.528388904423625e-05, 'mask_type': 'sparsemax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16: Global AUC = 0.7529, Accuracy = 0.6800, F1 = 0.7209\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.92857\n",
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 32 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:36:02,771] Trial 17 finished with value: 0.7642857142857142 and parameters: {'n_d': 48, 'n_a': 56, 'n_steps': 8, 'gamma': 1.3269893813285565, 'lambda_sparse': 0.000756813439972642, 'momentum': 0.19106435398770102, 'lr': 0.011227781414267628, 'weight_decay': 2.9193087850645127e-06, 'mask_type': 'sparsemax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 17: Global AUC = 0.7643, Accuracy = 0.7200, F1 = 0.7470\n",
      "\n",
      "Early stopping occurred at epoch 77 with best_epoch = 57 and best_val_0_auc = 0.875\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_auc = 0.92593\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 1.0\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:37:02,345] Trial 18 finished with value: 0.7671428571428571 and parameters: {'n_d': 56, 'n_a': 64, 'n_steps': 5, 'gamma': 1.4050766132689663, 'lambda_sparse': 0.008340573090698123, 'momentum': 0.31043901524877016, 'lr': 0.005407408817280763, 'weight_decay': 7.936816333009611e-05, 'mask_type': 'sparsemax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.76\n",
      "Trial 18: Global AUC = 0.7671, Accuracy = 0.7200, F1 = 0.7200\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.76786\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 35 and best_val_0_auc = 0.72222\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.71429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:37:34,235] Trial 19 finished with value: 0.6735714285714286 and parameters: {'n_d': 48, 'n_a': 32, 'n_steps': 3, 'gamma': 1.6230981042930162, 'lambda_sparse': 0.0008142673944590973, 'momentum': 0.22009200474480292, 'lr': 0.0010707330979327287, 'weight_decay': 0.002569583916444839, 'mask_type': 'sparsemax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.7\n",
      "Trial 19: Global AUC = 0.6736, Accuracy = 0.5867, F1 = 0.5974\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.75\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 1.0\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.67857\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_val_0_auc = 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:38:39,427] Trial 20 finished with value: 0.7571428571428571 and parameters: {'n_d': 24, 'n_a': 48, 'n_steps': 8, 'gamma': 1.1841265514418762, 'lambda_sparse': 0.003091461788915234, 'momentum': 0.34962630659542754, 'lr': 0.00956494413418543, 'weight_decay': 0.000303390072072776, 'mask_type': 'sparsemax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20: Global AUC = 0.7571, Accuracy = 0.7467, F1 = 0.7595\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.80357\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.92593\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:39:46,949] Trial 21 finished with value: 0.7892857142857143 and parameters: {'n_d': 24, 'n_a': 40, 'n_steps': 9, 'gamma': 1.1105096530555667, 'lambda_sparse': 0.00014770455188679778, 'momentum': 0.3114690679745577, 'lr': 0.016073505816096813, 'weight_decay': 0.00021452980795940864, 'mask_type': 'entmax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 21: Global AUC = 0.7893, Accuracy = 0.6667, F1 = 0.6914\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.80357\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.92593\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:41:22,530] Trial 22 finished with value: 0.7742857142857144 and parameters: {'n_d': 24, 'n_a': 56, 'n_steps': 10, 'gamma': 1.23717939697419, 'lambda_sparse': 0.00013131364739089874, 'momentum': 0.28418489950232095, 'lr': 0.014420165979514963, 'weight_decay': 0.0001443554325650901, 'mask_type': 'entmax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 22: Global AUC = 0.7743, Accuracy = 0.6800, F1 = 0.7143\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.92593\n",
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 7 and best_val_0_auc = 0.87037\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.67857\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:42:34,456] Trial 23 finished with value: 0.7114285714285714 and parameters: {'n_d': 32, 'n_a': 40, 'n_steps': 9, 'gamma': 1.3752211592830055, 'lambda_sparse': 5.737608255790802e-05, 'momentum': 0.255429713153207, 'lr': 0.014854728595710555, 'weight_decay': 0.0005095636925855612, 'mask_type': 'entmax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 23: Global AUC = 0.7114, Accuracy = 0.6800, F1 = 0.7209\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.71429\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:43:52,738] Trial 24 finished with value: 0.7121428571428572 and parameters: {'n_d': 16, 'n_a': 48, 'n_steps': 10, 'gamma': 1.108607089948227, 'lambda_sparse': 0.0011660085575608626, 'momentum': 0.3820113845108445, 'lr': 0.007939087922735177, 'weight_decay': 2.6355615758854415e-05, 'mask_type': 'sparsemax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 24: Global AUC = 0.7121, Accuracy = 0.6000, F1 = 0.6053\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.82143\n",
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 59 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.75\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 42 and best_val_0_auc = 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:45:34,871] Trial 25 finished with value: 0.7685714285714286 and parameters: {'n_d': 40, 'n_a': 32, 'n_steps': 7, 'gamma': 1.2355054312834768, 'lambda_sparse': 0.0005236492338953976, 'momentum': 0.30504312879087225, 'lr': 0.010422404348411842, 'weight_decay': 8.9122368848675e-05, 'mask_type': 'sparsemax'}. Best is trial 14 with value: 0.7907142857142857.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25: Global AUC = 0.7686, Accuracy = 0.7067, F1 = 0.7250\n",
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 6 and best_val_0_auc = 0.875\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.92593\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.75\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:46:29,759] Trial 26 finished with value: 0.8242857142857142 and parameters: {'n_d': 64, 'n_a': 56, 'n_steps': 6, 'gamma': 1.1185256502362655, 'lambda_sparse': 0.00439759127500796, 'momentum': 0.2387740279635065, 'lr': 0.015268495033849182, 'weight_decay': 0.001704976032165048, 'mask_type': 'entmax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 26: Global AUC = 0.8243, Accuracy = 0.7467, F1 = 0.7711\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.85714\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 92 with best_epoch = 72 and best_val_0_auc = 0.90741\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.73214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:47:44,960] Trial 27 finished with value: 0.7564285714285715 and parameters: {'n_d': 64, 'n_a': 56, 'n_steps': 4, 'gamma': 1.3927981703636054, 'lambda_sparse': 0.004764939608779906, 'momentum': 0.2322593874629873, 'lr': 0.0071641566232372575, 'weight_decay': 0.0017584553840309567, 'mask_type': 'sparsemax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.88\n",
      "Trial 27: Global AUC = 0.7564, Accuracy = 0.6800, F1 = 0.6757\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.94643\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.90741\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.92593\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 1.0\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:49:16,304] Trial 28 finished with value: 0.7857142857142857 and parameters: {'n_d': 56, 'n_a': 64, 'n_steps': 6, 'gamma': 1.2729178095177263, 'lambda_sparse': 0.0018316244574516545, 'momentum': 0.17755157672128405, 'lr': 0.004997556110743856, 'weight_decay': 0.000639899858291144, 'mask_type': 'entmax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 28: Global AUC = 0.7857, Accuracy = 0.7200, F1 = 0.7342\n",
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 24 and best_val_0_auc = 0.91071\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 35 and best_val_0_auc = 0.92593\n",
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.90741\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.78571\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:51:04,396] Trial 29 finished with value: 0.802142857142857 and parameters: {'n_d': 64, 'n_a': 64, 'n_steps': 5, 'gamma': 1.5683747158243755, 'lambda_sparse': 0.004160441041602411, 'momentum': 0.1551473266779078, 'lr': 0.014634014430542339, 'weight_decay': 4.990399226548232e-06, 'mask_type': 'sparsemax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 29: Global AUC = 0.8021, Accuracy = 0.7733, F1 = 0.7952\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.75\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_val_0_auc = 0.83333\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.80357\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 42 and best_val_0_auc = 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:52:50,845] Trial 30 finished with value: 0.6864285714285714 and parameters: {'n_d': 64, 'n_a': 64, 'n_steps': 6, 'gamma': 1.5515834655897989, 'lambda_sparse': 0.009418568327824133, 'momentum': 0.15219655615309788, 'lr': 0.013092629478415408, 'weight_decay': 5.3437432880423615e-06, 'mask_type': 'sparsemax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30: Global AUC = 0.6864, Accuracy = 0.6133, F1 = 0.6133\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.91071\n",
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 19 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 20 with best_epoch = 0 and best_val_0_auc = 0.73214\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:53:53,892] Trial 31 finished with value: 0.7621428571428572 and parameters: {'n_d': 56, 'n_a': 56, 'n_steps': 5, 'gamma': 1.5275865645473277, 'lambda_sparse': 0.004019834350623378, 'momentum': 0.2089315171926887, 'lr': 0.017092207541551857, 'weight_decay': 4.588238049047159e-05, 'mask_type': 'sparsemax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 31: Global AUC = 0.7621, Accuracy = 0.6533, F1 = 0.6579\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.82143\n",
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 12 and best_val_0_auc = 0.90741\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 26 and best_val_0_auc = 1.0\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.64286\n",
      "\n",
      "Early stopping occurred at epoch 24 with best_epoch = 4 and best_val_0_auc = 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:55:11,309] Trial 32 finished with value: 0.7314285714285714 and parameters: {'n_d': 64, 'n_a': 64, 'n_steps': 5, 'gamma': 1.6658896836030455, 'lambda_sparse': 0.0022168480113434865, 'momentum': 0.0852187756620261, 'lr': 0.008912570552334517, 'weight_decay': 2.813222739411574e-05, 'mask_type': 'sparsemax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 32: Global AUC = 0.7314, Accuracy = 0.6933, F1 = 0.7229\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.85714\n",
      "\n",
      "Early stopping occurred at epoch 21 with best_epoch = 1 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 18 and best_val_0_auc = 1.0\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.67857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:56:18,274] Trial 33 finished with value: 0.7821428571428571 and parameters: {'n_d': 56, 'n_a': 64, 'n_steps': 4, 'gamma': 1.4319452448423204, 'lambda_sparse': 0.00111274414949019, 'momentum': 0.1932123434554708, 'lr': 0.01392952337129065, 'weight_decay': 1.2374044685193048e-06, 'mask_type': 'sparsemax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 17 and best_val_0_auc = 0.9\n",
      "Trial 33: Global AUC = 0.7821, Accuracy = 0.6800, F1 = 0.6842\n",
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 14 and best_val_0_auc = 0.875\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.98148\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.73214\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:57:59,611] Trial 34 finished with value: 0.7614285714285713 and parameters: {'n_d': 48, 'n_a': 56, 'n_steps': 6, 'gamma': 1.5788699487132587, 'lambda_sparse': 0.004685874340092623, 'momentum': 0.13895115053749044, 'lr': 0.0025052971043350927, 'weight_decay': 6.079503370820727e-06, 'mask_type': 'sparsemax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 34: Global AUC = 0.7614, Accuracy = 0.7333, F1 = 0.7436\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.75\n",
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 42 and best_val_0_auc = 0.90741\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.87037\n",
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 34 and best_val_0_auc = 0.80357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 12:59:16,507] Trial 35 finished with value: 0.7249999999999999 and parameters: {'n_d': 64, 'n_a': 48, 'n_steps': 4, 'gamma': 1.868369852537795, 'lambda_sparse': 0.006410198860149005, 'momentum': 0.17171971909310665, 'lr': 0.010685487121288119, 'weight_decay': 0.0032421600184109212, 'mask_type': 'sparsemax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.8\n",
      "Trial 35: Global AUC = 0.7250, Accuracy = 0.6000, F1 = 0.6154\n",
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 25 and best_val_0_auc = 0.83929\n",
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 11 and best_val_0_auc = 0.90741\n",
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 13 and best_val_0_auc = 0.85185\n",
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 5 and best_val_0_auc = 0.60714\n",
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 27 and best_val_0_auc = 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-24 13:00:54,654] Trial 36 finished with value: 0.7664285714285715 and parameters: {'n_d': 56, 'n_a': 64, 'n_steps': 7, 'gamma': 1.3527722576058043, 'lambda_sparse': 0.003699467963412427, 'momentum': 0.11440995233732523, 'lr': 0.017866701797471258, 'weight_decay': 0.009767681346879763, 'mask_type': 'sparsemax'}. Best is trial 26 with value: 0.8242857142857142.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 36: Global AUC = 0.7664, Accuracy = 0.7067, F1 = 0.7250\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.80357\n",
      "\n",
      "Early stopping occurred at epoch 23 with best_epoch = 3 and best_val_0_auc = 0.94444\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 66 and best_val_0_auc = 0.88889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-04-24 13:01:59,931] Trial 37 failed with parameters: {'n_d': 64, 'n_a': 56, 'n_steps': 5, 'gamma': 1.683919659275522, 'lambda_sparse': 0.002380518927422153, 'momentum': 0.15992899813063532, 'lr': 0.004243765037963861, 'weight_decay': 6.668774492519852e-05, 'mask_type': 'entmax'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\AppData\\Local\\Temp\\ipykernel_20820\\2116535040.py\", line 72, in objective_tabnet\n",
      "    clf.fit(\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 262, in fit\n",
      "    self._predict_epoch(eval_name, valid_dataloader)\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 562, in _predict_epoch\n",
      "    scores = self._predict_batch(X)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 590, in _predict_batch\n",
      "    scores, _ = self.network(X)\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 616, in forward\n",
      "    return self.tabnet(x)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 492, in forward\n",
      "    steps_output, M_loss = self.encoder(x)\n",
      "                           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 169, in forward\n",
      "    att = self.initial_splitter(x)[:, self.n_d :]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 737, in forward\n",
      "    x = self.shared(x)\n",
      "        ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 774, in forward\n",
      "    x = self.glu_layers[0](x)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 804, in forward\n",
      "    x = self.bn(x)\n",
      "        ^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Sarvesh\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 35, in forward\n",
      "    chunks = x.chunk(int(np.ceil(x.shape[0] / self.virtual_batch_size)), 0)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-24 13:01:59,940] Trial 37 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 121\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Run the Optuna study\u001b[39;00m\n\u001b[0;32m    120\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m--> 121\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective_tabnet, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Print best results\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest AUC:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_value)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     _optimize(\n\u001b[0;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    485\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[23], line 72\u001b[0m, in \u001b[0;36mobjective_tabnet\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     62\u001b[0m X_train_resampled, y_train_resampled \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[0;32m     64\u001b[0m clf \u001b[38;5;241m=\u001b[39m TabNetClassifier(\n\u001b[0;32m     65\u001b[0m     n_d\u001b[38;5;241m=\u001b[39mn_d, n_a\u001b[38;5;241m=\u001b[39mn_a, n_steps\u001b[38;5;241m=\u001b[39mn_steps,\n\u001b[0;32m     66\u001b[0m     gamma\u001b[38;5;241m=\u001b[39mgamma, lambda_sparse\u001b[38;5;241m=\u001b[39mlambda_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, device_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     70\u001b[0m )\n\u001b[1;32m---> 72\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m     73\u001b[0m     X_train_resampled\u001b[38;5;241m.\u001b[39mvalues, y_train_resampled\u001b[38;5;241m.\u001b[39mvalues,\n\u001b[0;32m     74\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[(X_test\u001b[38;5;241m.\u001b[39mvalues, y_test\u001b[38;5;241m.\u001b[39mvalues)],\n\u001b[0;32m     75\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     76\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     77\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, virtual_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[0;32m     78\u001b[0m )\n\u001b[0;32m     80\u001b[0m X_test_flip \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mX_test\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     81\u001b[0m y_probs_flip \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test_flip)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:262\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_epoch(eval_name, valid_dataloader)\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Call method on_epoch_end for all callbacks\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_epoch_end(\n\u001b[0;32m    266\u001b[0m     epoch_idx, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mepoch_metrics\n\u001b[0;32m    267\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:562\u001b[0m, in \u001b[0;36mTabModel._predict_epoch\u001b[1;34m(self, name, loader)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# Main loop\u001b[39;00m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m--> 562\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_batch(X)\n\u001b[0;32m    563\u001b[0m     list_y_true\u001b[38;5;241m.\u001b[39mappend(y)\n\u001b[0;32m    564\u001b[0m     list_y_score\u001b[38;5;241m.\u001b[39mappend(scores)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:590\u001b[0m, in \u001b[0;36mTabModel._predict_batch\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    587\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m    589\u001b[0m \u001b[38;5;66;03m# compute model output\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m scores, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork(X)\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scores, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    593\u001b[0m     scores \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m scores]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:616\u001b[0m, in \u001b[0;36mTabNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    615\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(x)\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtabnet(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:492\u001b[0m, in \u001b[0;36mTabNetNoEmbeddings.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    491\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 492\u001b[0m     steps_output, M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m    493\u001b[0m     res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mstack(steps_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_task:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;66;03m# Result will be in list format\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:169\u001b[0m, in \u001b[0;36mTabNetEncoder.forward\u001b[1;34m(self, x, prior)\u001b[0m\n\u001b[0;32m    166\u001b[0m     prior \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((bs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_dim))\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    168\u001b[0m M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 169\u001b[0m att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_splitter(x)[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_d :]\n\u001b[0;32m    170\u001b[0m steps_output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:737\u001b[0m, in \u001b[0;36mFeatTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 737\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared(x)\n\u001b[0;32m    738\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecifics(x)\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:774\u001b[0m, in \u001b[0;36mGLU_Block.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    772\u001b[0m scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m0.5\u001b[39m])\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst:  \u001b[38;5;66;03m# the first layer of the block has no scale multiplication\u001b[39;00m\n\u001b[1;32m--> 774\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglu_layers[\u001b[38;5;241m0\u001b[39m](x)\n\u001b[0;32m    775\u001b[0m     layers_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_glu)\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:804\u001b[0m, in \u001b[0;36mGLU_Layer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    803\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[1;32m--> 804\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x)\n\u001b[0;32m    805\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(x[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim], torch\u001b[38;5;241m.\u001b[39msigmoid(x[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim :]))\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\NBACluster\\Lib\\site-packages\\pytorch_tabnet\\tab_network.py:35\u001b[0m, in \u001b[0;36mGBN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 35\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size)), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     36\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x_) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# Ensure save directory exists\n",
    "os.makedirs(\"saved_models\", exist_ok=True)\n",
    "\n",
    "years = np.arange(2020, 2025)\n",
    "\n",
    "def objective_tabnet(trial):\n",
    "    \n",
    "    n_d = trial.suggest_int(\"n_d\", 8, 64, step=8)\n",
    "    n_a = trial.suggest_int(\"n_a\", 8, 64, step=8)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 3, 10)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1.0, 2.0)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 0.00001, 0.01, log=True)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.01, 0.4)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-3, 2e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", ['sparsemax', 'entmax'])\n",
    "    \n",
    "\n",
    "    '''\n",
    "    n_d = trial.suggest_int(\"n_d\", 40, 56, step=4)\n",
    "    n_a = trial.suggest_int(\"n_a\", 40, 56, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 6, 10)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1.0, 1.2)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-5, 1e-3, log=True)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.3, 0.4)\n",
    "    lr = trial.suggest_float(\"lr\", 0.001, 0.003, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-5, log=True)\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", ['sparsemax', 'entmax'])\n",
    "    '''\n",
    "\n",
    "    # Store predictions and true labels for global metrics\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "    all_y_prob = []\n",
    "\n",
    "    for year in years:\n",
    "        train_data = diff_df[diff_df['SEASON'] < year]\n",
    "        test_data = diff_df[diff_df['SEASON'] == year]\n",
    "\n",
    "        if train_data.empty or test_data.empty:\n",
    "            continue\n",
    "\n",
    "        X_train = train_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "        y_train = train_data['TEAM_1_W']\n",
    "        X_test = test_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "        y_test = test_data['TEAM_1_W']\n",
    "\n",
    "        \n",
    "\n",
    "        smote = SMOTE(random_state=10)\n",
    "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        clf = TabNetClassifier(\n",
    "            n_d=n_d, n_a=n_a, n_steps=n_steps,\n",
    "            gamma=gamma, lambda_sparse=lambda_sparse,\n",
    "            momentum=momentum, mask_type=mask_type,\n",
    "            optimizer_params={\"lr\": lr, \"weight_decay\": weight_decay},\n",
    "            seed=10, verbose=0, device_name='cpu'\n",
    "        )\n",
    "\n",
    "        clf.fit(\n",
    "            X_train_resampled.values, y_train_resampled.values,\n",
    "            eval_set=[(X_test.values, y_test.values)],\n",
    "            eval_metric=['auc'],\n",
    "            max_epochs=200, patience=20,\n",
    "            batch_size=64, virtual_batch_size=32\n",
    "        )\n",
    "\n",
    "        X_test_flip = -X_test.values\n",
    "        y_probs_flip = clf.predict_proba(X_test_flip)[:, 1]\n",
    "\n",
    "        # Symmetric inference: average regular and 1 - flipped\n",
    "        symmetric_probs = (clf.predict_proba(X_test.values)[:, 1] + (1 - y_probs_flip)) / 2\n",
    "        y_pred = (symmetric_probs >= 0.5).astype(int)\n",
    "\n",
    "        #y_probs = clf.predict_proba(X_test.values)[:, 1]\n",
    "        #y_pred = (y_probs >= 0.5).astype(int)\n",
    "\n",
    "        #preds_label = clf.predict(X_test.values)\n",
    "\n",
    "        # Collect for global metrics\n",
    "        all_y_true.extend(y_test.values)\n",
    "        all_y_pred.extend(y_pred)\n",
    "        all_y_prob.extend(symmetric_probs)\n",
    "\n",
    "    if len(all_y_true) == 0:\n",
    "        # Skip trial if no data\n",
    "        return 0.0\n",
    "\n",
    "    # Compute global metrics\n",
    "    global_auc = roc_auc_score(all_y_true, all_y_prob)\n",
    "    global_accuracy = accuracy_score(all_y_true, all_y_pred)\n",
    "    global_f1 = f1_score(all_y_true, all_y_pred)\n",
    "\n",
    "    print(f\"Trial {trial.number}: Global AUC = {global_auc:.4f}, Accuracy = {global_accuracy:.4f}, F1 = {global_f1:.4f}\")\n",
    "\n",
    "    \n",
    "    #  Save models with high AUC\n",
    "    if global_auc >= 0.90:\n",
    "        filename = f\"tabnet_trial{trial.number}_auc{global_auc:.4f}.zip\"\n",
    "        filepath = os.path.join(\"saved_models\", filename)\n",
    "        clf.save_model(filepath)\n",
    "        print(f\" Saved model for Trial {trial.number}  {filename}\")\n",
    "    \n",
    "\n",
    "    return global_auc\n",
    "\n",
    "# Run the Optuna study\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=8))\n",
    "study.optimize(objective_tabnet, n_trials=200)\n",
    "\n",
    "# Print best results\n",
    "print(\"Best AUC:\", study.best_value)\n",
    "print(\"Best Params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b502659a-0ee6-4641-b5a8-a37ee86aed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating year: 2020\n",
      "\n",
      "Early stopping occurred at epoch 46 with best_epoch = 26 and best_val_0_auc = 0.875\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.92857\n",
      "AUC: 0.8393 | Accuracy: 0.8000 | F1: 0.8235\n",
      "Binary Cross-Entropy Loss: 0.5730\n",
      "Confusion Matrix:\n",
      "[[5 2]\n",
      " [1 7]]\n",
      "\n",
      " Evaluating year: 2021\n",
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 10 and best_val_0_auc = 0.88889\n",
      "\n",
      "Early stopping occurred at epoch 41 with best_epoch = 21 and best_val_0_auc = 0.7963\n",
      "AUC: 0.8889 | Accuracy: 0.8667 | F1: 0.8571\n",
      "Binary Cross-Entropy Loss: 0.5945\n",
      "Confusion Matrix:\n",
      "[[7 2]\n",
      " [0 6]]\n",
      "\n",
      " Evaluating year: 2022\n",
      "\n",
      "Early stopping occurred at epoch 29 with best_epoch = 9 and best_val_0_auc = 0.92593\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_val_0_auc = 0.96296\n",
      "AUC: 1.0000 | Accuracy: 0.8667 | F1: 0.8750\n",
      "Binary Cross-Entropy Loss: 0.4970\n",
      "Confusion Matrix:\n",
      "[[6 0]\n",
      " [2 7]]\n",
      "\n",
      " Evaluating year: 2023\n",
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 8 and best_val_0_auc = 0.96429\n",
      "\n",
      "Early stopping occurred at epoch 22 with best_epoch = 2 and best_val_0_auc = 0.89286\n",
      "AUC: 0.9464 | Accuracy: 0.9333 | F1: 0.9231\n",
      "Binary Cross-Entropy Loss: 0.4906\n",
      "Confusion Matrix:\n",
      "[[8 0]\n",
      " [1 6]]\n",
      "\n",
      " Evaluating year: 2024\n",
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 15 and best_val_0_auc = 0.94\n",
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 16 and best_val_0_auc = 1.0\n",
      "AUC: 0.9200 | Accuracy: 0.8667 | F1: 0.8889\n",
      "Binary Cross-Entropy Loss: 0.5184\n",
      "Confusion Matrix:\n",
      "[[5 0]\n",
      " [2 8]]\n",
      "\n",
      " Overall Blended Model Performance:\n",
      "AUC: 0.9057, Accuracy: 0.8667, F1: 0.8718, Precision: 0.8947, Recall: 0.8500\n",
      "Overall Binary Cross-Entropy Loss: 0.5347\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, confusion_matrix, precision_score, recall_score, log_loss\n",
    "import numpy as np\n",
    "\n",
    "# Tracking\n",
    "all_y_true = []\n",
    "all_y_prob_blended = []\n",
    "all_y_pred_blended = []\n",
    "\n",
    "# Per-year metrics\n",
    "yearly_metrics = []\n",
    "\n",
    "years = np.arange(2020, 2025)\n",
    "\n",
    "# 84% accuracy set (2020-2025 test), 0.883 AUC, threshold = 0.5, seed = 8 (fit, optuna)\n",
    "params_a = {\n",
    "    'n_d': 56,\n",
    "    'n_a': 64,\n",
    "    'n_steps': 6,\n",
    "    'gamma': 1.3930814539055605,\n",
    "    'lambda_sparse': 0.0029833605183872134,\n",
    "    'momentum': 0.15891701764952307,\n",
    "    'mask_type': 'entmax'\n",
    "}\n",
    "\n",
    "opt_params_a = {\n",
    "    'lr': 0.0076661428463103455,\n",
    "    'weight_decay': 2.501056095511525e-05\n",
    "}\n",
    "\n",
    "# 85% accuracy set (2020-2025 test), 0.89 AUC, threshold = 0.51, seed = 10 (fit, optuna)\n",
    "params_b = {\n",
    "    'n_d': 48,\n",
    "    'n_a': 48,\n",
    "    'n_steps': 8,\n",
    "    'gamma': 1.0950455922432034,\n",
    "    'lambda_sparse': 0.000365814411562923,\n",
    "    'momentum': 0.3675391603570311,\n",
    "    'mask_type': 'sparsemax'\n",
    "}\n",
    "\n",
    "opt_params_b = {\n",
    "    'lr': 0.002071649487926403,\n",
    "    'weight_decay': 4.2583833531711615e-06\n",
    "}\n",
    "\n",
    "# 79% accuracy set (2005-2005 test), 0.869 AUC, threshold = 0.5, seed = 5 (fit, optuna) \n",
    "params_c = {\n",
    "    'n_d': 48,\n",
    "    'n_a': 32,\n",
    "    'n_steps': 5,\n",
    "    'gamma': 1.1885687695822824,\n",
    "    'lambda_sparse': 0.0019929526182699384,\n",
    "    'momentum': 0.25773242436863386,\n",
    "    'mask_type': 'entmax'\n",
    "}\n",
    "\n",
    "opt_params_c = {\n",
    "    'lr': 0.01601995480535204,\n",
    "    'weight_decay': 0.00015417059849810502,\n",
    "}\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    print(f\"\\n Evaluating year: {year}\")\n",
    "    train_data = diff_df[diff_df['SEASON'] < year]\n",
    "    test_data = diff_df[diff_df['SEASON'] == year]\n",
    "    \n",
    "    if train_data.empty or test_data.empty:\n",
    "        continue\n",
    "\n",
    "    X_train = train_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "    y_train = train_data['TEAM_1_W']\n",
    "    X_test = test_data.drop(columns=['TEAM_1_W', 'SEASON'])\n",
    "    y_test = test_data['TEAM_1_W']\n",
    "\n",
    "    smote = SMOTE(random_state=10)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # -------- Model A --------\n",
    "    model_a = TabNetClassifier(\n",
    "        **params_a,\n",
    "        optimizer_params=opt_params_a,\n",
    "        seed=8,\n",
    "        device_name='cpu',\n",
    "        verbose=0\n",
    "    )\n",
    "    model_a.fit(\n",
    "        X_train_resampled.values, y_train_resampled.values,\n",
    "        eval_set=[(X_test.values, y_test.values)],\n",
    "        eval_metric=['auc'],\n",
    "        max_epochs=200, patience=20,\n",
    "        batch_size=64, virtual_batch_size=32\n",
    "    )\n",
    "    probs_a = model_a.predict_proba(X_test.values)[:, 1]\n",
    "    \n",
    "    \n",
    "    # -------- Model B --------\n",
    "    model_b = TabNetClassifier(\n",
    "        **params_b,\n",
    "        optimizer_params=opt_params_b,\n",
    "        seed=10,\n",
    "        device_name='cpu',\n",
    "        verbose=0\n",
    "    )\n",
    "    model_b.fit(\n",
    "        X_train_resampled.values, y_train_resampled.values,\n",
    "        eval_set=[(X_test.values, y_test.values)],\n",
    "        eval_metric=['auc'],\n",
    "        max_epochs=200, patience=20,\n",
    "        batch_size=64, virtual_batch_size=32\n",
    "    )\n",
    "    probs_b = model_b.predict_proba(X_test.values)[:, 1]\n",
    "    \n",
    "    '''\n",
    "    # -------- Model C --------\n",
    "    model_c = TabNetClassifier(\n",
    "        **params_c,\n",
    "        optimizer_params=opt_params_c,\n",
    "        seed=5,\n",
    "        device_name='cpu',\n",
    "        verbose=0\n",
    "    )\n",
    "    model_c.fit(\n",
    "        X_train_resampled.values, y_train_resampled.values,\n",
    "        eval_set=[(X_test.values, y_test.values)],\n",
    "        eval_metric=['auc'],\n",
    "        max_epochs=200, patience=20,\n",
    "        batch_size=64, virtual_batch_size=32\n",
    "    )\n",
    "    probs_c = model_c.predict_proba(X_test.values)[:, 1]\n",
    "    '''\n",
    "    \n",
    "    X_test_flipped = -X_test.values\n",
    "\n",
    "    '''\n",
    "    # -------- Blend Predictions --------\n",
    "    blended_probs = (probs_a + probs_b) / 2\n",
    "    blended_preds = (blended_probs >= 0.505).astype(int)\n",
    "    '''\n",
    "\n",
    "    # Flip all the features by negating them\n",
    "    X_test_flipped = -X_test.values\n",
    "\n",
    "    # Get predictions for flipped inputs\n",
    "    probs_a_flip = model_a.predict_proba(X_test_flipped)[:, 1]\n",
    "    probs_b_flip = model_b.predict_proba(X_test_flipped)[:, 1]\n",
    "    probs_c_flip = model_a.predict_proba(X_test_flipped)[:, 1]\n",
    "    \n",
    "    # Blend forward and flipped predictions separately\n",
    "    blended_forward = (probs_a + probs_b) / 2\n",
    "    blended_flipped = 1 - ((probs_a_flip + probs_b_flip) / 2)  # invert because flipped input reverses label\n",
    "\n",
    "    # Final symmetric probability: average of regular and flipped\n",
    "    symmetric_probs = (blended_forward + blended_flipped) / 2\n",
    "\n",
    "    # Convert to binary predictions using threshold\n",
    "    blended_preds = (symmetric_probs >= 0.52).astype(int)\n",
    "    blended_probs = symmetric_probs\n",
    "\n",
    "    bce_loss = log_loss(y_test, blended_probs)\n",
    "\n",
    "    # Metrics for this year\n",
    "    auc = roc_auc_score(y_test, blended_probs)\n",
    "    acc = accuracy_score(y_test, blended_preds)\n",
    "    f1 = f1_score(y_test, blended_preds)\n",
    "    cm = confusion_matrix(y_test, blended_preds)\n",
    "\n",
    "    print(f\"AUC: {auc:.4f} | Accuracy: {acc:.4f} | F1: {f1:.4f}\")\n",
    "    print(f\"Binary Cross-Entropy Loss: {bce_loss:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    yearly_metrics.append({\n",
    "        \"year\": year,\n",
    "        \"auc\": auc,\n",
    "        \"accuracy\": acc,\n",
    "        \"f1\": f1,\n",
    "        \"confusion_matrix\": cm\n",
    "    })\n",
    "\n",
    "    # Global tracking\n",
    "    all_y_true.extend(y_test)\n",
    "    all_y_prob_blended.extend(blended_probs)\n",
    "    all_y_pred_blended.extend(blended_preds)\n",
    "\n",
    "# ------ Overall Metrics ------\n",
    "overall_auc = roc_auc_score(all_y_true, all_y_prob_blended)\n",
    "overall_acc = accuracy_score(all_y_true, all_y_pred_blended)\n",
    "overall_f1 = f1_score(all_y_true, all_y_pred_blended)\n",
    "overall_prec = precision_score(all_y_true, all_y_pred_blended)\n",
    "overall_rec = recall_score(all_y_true, all_y_pred_blended)\n",
    "overall_bce_loss = log_loss(all_y_true, all_y_prob_blended)\n",
    "\n",
    "print(f\"\\n Overall Blended Model Performance:\")\n",
    "print(f\"AUC: {overall_auc:.4f}, Accuracy: {overall_acc:.4f}, F1: {overall_f1:.4f}, Precision: {overall_prec:.4f}, Recall: {overall_rec:.4f}\")\n",
    "print(f\"Overall Binary Cross-Entropy Loss: {overall_bce_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e32323e-8be3-413e-9381-3ac2d57cefab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (NBACluster)",
   "language": "python",
   "name": "nbacluster"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
